{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture-7: Neural Networks Basics\n",
    "## Under the supervision of Dr. Manish Shrivastava"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topics covered so far\n",
    "\n",
    "* Lecture - 1: Python basics includes list, tuple, dictionary, loops and functions\n",
    "* Lecture - 2: Additional concepts in python, Introduction to Numpy, pandas, and matplotlib\n",
    "* Lecture - 3: Regular expressions, stop words, lemmatization, stemming, Tokenization and\n",
    "Challenges in tokenization\n",
    "* Lecture - 4: Spelling mistake detection and correction with minimum edit distance, Chunking\n",
    "and NER, POS tagging\n",
    "* Lecture - 5: Language Modeling, Smoothing\n",
    "* Lecture - 6: Word Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topics covered in this lecture\n",
    "\n",
    "1. Introduction\n",
    "    - Biological neuron\n",
    "    - Artificial Neuron (perceptron model)\n",
    "    - Explain terms in a perceptron\n",
    "    - Purpose of bias and activation functions\n",
    "    - Activation Units\n",
    "    - Loss functions\n",
    "    - Define forward and backward propagation\n",
    "2. Training a single neuron model \n",
    "    - Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " ### 1.  Introduction\n",
    "\n",
    "- Artificial Neural Networks are inspired from the biological activities of Humans and animals like monkeys, ants etc\n",
    "\n",
    "\n",
    "- The core idea of Artificial Neural Networks is to mimic some part/functionality of human brain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The simplest Neural Network model called \"Perceptron\" was designed by Rosenblatt in 1957.\n",
    "\n",
    "- It has wide range of applications in this modern deep learning era. some of them are\n",
    "\n",
    "    - Voice Assistants (Apple Siri, Amazon Alexa, Cortana)\n",
    "    - Natural Language Processing (Abstractive Summarization, Question Answering)\n",
    "    - Self Driving Cars (Tesla, Google Waymo)\n",
    "    - Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###                                           Artificial Neuron vs Biological Neuron\n",
    "\n",
    "<img src=\"bn.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "- In biological neurons, all the inputs/signals received at dendrites are collected at the cell body.\n",
    "- Operations are performed on the net input collected at the cell body.\n",
    "- The results are carried through axon to synapses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain terms in perceptron\n",
    "\n",
    "<img src=\"an.jpeg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "- similar to biological neuron, in artificial neuron, \n",
    "\n",
    "    - the input values <b>{x1, · · · , xk}</b> are multiplied with their corresponding weigths <b>{w1, · · · , wk}</b>\n",
    "    - the net input is passed through activation function <b>f</b>, where the opeartions are performed on the net input.\n",
    "    - the resultant output of activation function is stored in <b>y</b>. \n",
    "\n",
    "        - <b>y = f(u)</b>\n",
    "\n",
    "        - <b>u</b> is the net input of the neuron, defined as $u=\\sum_{i=0}^K wi.xi \\$\n",
    "\n",
    "        - using vector notation, we can write, $u=w^T x$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role of Bias in Neural Networks\n",
    "\n",
    "- It allows you to move the line down and up fitting the prediction with the data better. If the constant c is absent then the line will pass through the origin (0, 0) and you will get a poorer fit.\n",
    "\n",
    "<img src=\"bias.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "\n",
    "- It is used to determine the output of neural network like yes or no. It maps the resulting values in between 0 to 1 or -1 to 1 etc. Different activation functions result in distinct behaviors of the neuron\n",
    "\n",
    "- The Activation Functions can be basically divided into 2 types-\n",
    "\n",
    "    1. Linear Activation Functions\n",
    "    2. Non-linear Activation Functions\n",
    "    \n",
    "<img src=\"linear-nonlinear.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Linear Activation Functions\n",
    "\n",
    "    - Unit Step Function \n",
    "    \\begin{equation}\n",
    "    f(u) =\n",
    "    \\begin{cases}\n",
    "      1 & \\text{if u>0}\\\\\n",
    "      0 & \\text{otherwise}\n",
    "    \\end{cases}       \n",
    "    \\end{equation}\n",
    "\n",
    "        - A neuron with this activation function is called a <b>perceptron</b>\n",
    "        - Note that a perceptron is a linear classifier, it classifies given input as one of the classes belonging to [0,1]\n",
    "        - If we want to fit more complex functions, we need to use a non-linear model.\n",
    "\n",
    "<img src=\"linear.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-linear Activation Functions\n",
    "\n",
    "- The Nonlinear Activation Functions are the most used activation functions. \n",
    "- It makes it easy for the model to generalize or adapt with variety of data and to differentiate between the output.\n",
    "\n",
    "<img src=\"nonlinear.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have various kind of activation functions like sigmoid, tanh, reLu, leaky reLu, softmax..etc. Below mentioned few non-linear ativation functions\n",
    "\n",
    "<img src=\"act_func.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sigmoid activation function\n",
    "\n",
    "<img src=\"sig2.jpg\" alt=\"Drawing\" style=\"width: 650px;\"/>\n",
    "\n",
    "- The advantage of using sigmoid activation function is it's derivative can also be written interms of sigmoid. so, it is easy to compute derivatives(using Back Propogation) while updating weights of the network.\n",
    "\n",
    "- The output of sigmoid fucntion lies between 0 and 1 and derivatives of sigmoid function also lies between 0 and 1.\n",
    "\n",
    "- The disadvantage with this function is the probelm of vanishing gradient that occurs when you build deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tanh activation function\n",
    "\n",
    "<img src=\"tan2.jpg\" alt=\"Drawing\" style=\"width: 680px;\"/>\n",
    "\n",
    "- The advantage of using tanh activation function is it's derivative can also be written interms of tanh. so, it is easy to compute derivatives(using Back Propogation) while updating weights of the network.\n",
    "\n",
    "- The output of tanh fucntion lies between -1 and 1 and derivatives of tanh function lies between 0 and 1.\n",
    "- The disadvantage with this function is the probelm of vanishing gradient that occurs when you build deep neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ReLu activation function\n",
    "\n",
    "\n",
    "<img src=\"relu2.jpg\" alt=\"Drawing\" style=\"width: 680px;\"/>\n",
    "\n",
    "- The advantage of using ReLu activation function is, it overcomes the problem of vanishing gradient faced by sigmoid and tanh functions.\n",
    "\n",
    "- This is the most popular activation unit in deep learning era.\n",
    "\n",
    "- The disadvantage with this function is the probelm of dead activation that occurs when derivatives become 0.\n",
    "\n",
    "- To overcome this problem slightly modified version of Relu called leaky Relu is used. but, in most of the cases Relu activation gives good results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions\n",
    "\n",
    "- The objective of the network is to minimze the loss functions (or objective functions) during the training.\n",
    "- Let there are K output neurons. Let the true output/target be t and the prediction/output is o.\n",
    "\n",
    "<img src=\"mse.png\" alt=\"Drawing\"/>\n",
    "<img src=\"loss2.png\" alt=\"Drawing\"/>\n",
    "<img src=\"loss3.png\" alt=\"Drawing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this slide, we explain how the Perceptron works with Logic gates (AND, OR, NOT, and so on).\n",
    "\n",
    "<img src=\"xor.gif\" alt=\"Drawing\"/>\n",
    "<img src=\"XOR_gate.png\" alt=\"Drawing\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cost')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#logistic regression\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    " \n",
    "# Set inputs and correct output values\n",
    "inputs = [[0,0], [1,1], [0,1], [1,0]]\n",
    "outputs = [0, 0, 1, 1]\n",
    " \n",
    "# Set training parameters\n",
    "alpha = 0.1 # Learning rate\n",
    "training_iterations = 30000\n",
    " \n",
    "# Define tensors\n",
    "x = T.matrix(\"x\")\n",
    "y = T.vector(\"y\")\n",
    "b = theano.shared(value=1.0, name='b')\n",
    " \n",
    "# Set random seed\n",
    "rng = np.random.RandomState(2345)\n",
    " \n",
    "# Initialize random weights\n",
    "w_values = np.asarray(rng.uniform(low=-1, high=1, size=(2, 1)),\n",
    "                      dtype=theano.config.floatX) # Force type to 32bit float for GPU\n",
    "w = theano.shared(value=w_values, name='w', borrow=True)\n",
    " \n",
    "# Theano symbolic expressions\n",
    "hypothesis = T.nnet.sigmoid(T.dot(x, w) + b) # Sigmoid/logistic activation\n",
    "hypothesis = T.flatten(hypothesis) # This needs to be flattened so\n",
    "                                   # hypothesis (matrix) and\n",
    "                                   # y (vector) have the same shape\n",
    " \n",
    "cost = T.nnet.binary_crossentropy(hypothesis, y).mean() # Binary CE\n",
    "updates_rules = [\n",
    "    (w, w - alpha * T.grad(cost, wrt=w)),\n",
    "    (b, b - alpha * T.grad(cost, wrt=b))\n",
    "]\n",
    " \n",
    "# Theano compiled functions\n",
    "train = theano.function(inputs=[x, y], outputs=[hypothesis, cost],\n",
    "                        updates=updates_rules)\n",
    "predict = theano.function(inputs=[x], outputs=[hypothesis])\n",
    " \n",
    "# Training\n",
    "cost_history = []\n",
    " \n",
    "for i in range(training_iterations):\n",
    "    h, cost = train(inputs, outputs)\n",
    "    cost_history.append(cost)\n",
    "    \n",
    "# Plot training curve\n",
    "plt.plot(range(1, len(cost_history)+1), cost_history)\n",
    "plt.grid(True)\n",
    "plt.xlim(1, len(cost_history))\n",
    "plt.ylim(0, max(cost_history))\n",
    "plt.title(\"Training Curve\")\n",
    "plt.xlabel(\"Iteration #\")\n",
    "plt.ylabel(\"Cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set inputs and correct output values\n",
    "inputs = [[0,0], [1,1], [0,1], [1,0]]\n",
    "outputs = [0, 0, 1, 1]\n",
    "\n",
    "# Set training parameters\n",
    "alpha = 0.1  # Learning rate\n",
    "training_iterations = 50000\n",
    "hidden_layer_nodes = 3\n",
    "\n",
    " # Define tensors\n",
    "x = T.matrix(\"x\")\n",
    "y = T.vector(\"y\")\n",
    "b1 = theano.shared(value=1.0, name='b1')\n",
    "b2 = theano.shared(value=1.0, name='b2')\n",
    "\n",
    "# Set random seed\n",
    "rng = np.random.RandomState(2345)\n",
    "\n",
    "# Initialize weights\n",
    "w1_array = np.asarray(\n",
    "    rng.uniform(low=-1, high=1, size=(2, hidden_layer_nodes)),\n",
    "    dtype=theano.config.floatX)  # Force type to 32bit float for GPU\n",
    "w1 = theano.shared(value=w1_array, name='w1', borrow=True)\n",
    "\n",
    "w2_array = np.asarray(\n",
    "    rng.uniform(low=-1, high=1, size=(hidden_layer_nodes, 1)),\n",
    "    dtype=theano.config.floatX)  # Force type to 32bit float for GPU\n",
    "w2 = theano.shared(value=w2_array, name='w2', borrow=True)\n",
    "\n",
    "# Theano symbolic expressions\n",
    "a1 = T.nnet.sigmoid(T.dot(x, w1) + b1)  # Input -> Hidden\n",
    "a2 = T.nnet.sigmoid(T.dot(a1, w2) + b2)  # Hidden -> Output\n",
    "hypothesis = T.flatten(a2)  # This needs to be flattened so\n",
    "                            # hypothesis (matrix) and\n",
    "                            # y (vector) have the same shape\n",
    "\n",
    "# cost = T.sum((y - hypothesis) ** 2)  # Quadratic/squared error loss\n",
    "# cost = -(y*T.log(hypothesis) + (1-y)*T.log(1-hypothesis)).sum()  # Manual CE\n",
    "# cost = T.nnet.categorical_crossentropy(hypothesis, y)  # Categorical CE\n",
    "cost = T.nnet.binary_crossentropy(hypothesis, y).mean()  # Binary CE\n",
    "\n",
    "updates_rules = [\n",
    "    (w1, w1 - alpha * T.grad(cost, wrt=w1)),\n",
    "    (w2, w2 - alpha * T.grad(cost, wrt=w2)),\n",
    "    (b1, b1 - alpha * T.grad(cost, wrt=b1)),\n",
    "    (b2, b2 - alpha * T.grad(cost, wrt=b2))\n",
    "    ]\n",
    "\n",
    "# Theano compiled functions\n",
    "train = theano.function(inputs=[x, y], outputs=[hypothesis, cost],\n",
    "                        updates=updates_rules)\n",
    "predict = theano.function(inputs=[x], outputs=[hypothesis])\n",
    "\n",
    "# Training\n",
    "cost_history = []\n",
    "\n",
    "for i in range(training_iterations):\n",
    "    #if (i+1) % 5000 == 0:\n",
    "        #print \"Iteration #%s: \" % str(i+1)\n",
    "        #print \"Cost: %s\" % str(cost)\n",
    "    h, cost = train(inputs, outputs)\n",
    "    cost_history.append(cost)\n",
    "\n",
    "# Plot training curve\n",
    "plt.plot(range(1, len(cost_history)+1), cost_history)\n",
    "plt.grid(True)\n",
    "plt.xlim(1, len(cost_history))\n",
    "plt.ylim(0, max(cost_history))\n",
    "plt.title(\"Training Curve\")\n",
    "plt.xlabel(\"Iteration #\")\n",
    "plt.ylabel(\"Cost\")\n",
    "\n",
    "# Predictions\n",
    "test_data = [[0,0], [1,1], [0,1], [1,0]]\n",
    "predictions = predict(test_data)\n",
    "#print predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation and back propagation in a neural network\n",
    "\n",
    "- Using the input variables x and y, The forwardpass (left half of the figure) calculates output z as a function of x and y i.e. f(x,y)\n",
    "\n",
    "- The right side of the figures shows the backwardpass.\n",
    "\n",
    "- Receiving dL/dz (the derivative of the total loss with respect to the output z) , we can calculate the individual  gradients of x and y on the loss function by applying the chain rule, as shown in the figure.\n",
    "\n",
    "<img src=\"forward_backward.jpeg\" alt=\"Drawing\" style=\"width: 500px; height: 200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training a single neuron model\n",
    "### linear regression\n",
    "- Trainig a neural network means finding right set of weights.\n",
    "- Let us consider linear regression problem, which is a single neuron model.\n",
    "    - given dataset D={xi,yi} \n",
    "    - xi is a point in d-dimensional space and there are 'n' such points in dataset\n",
    "    - yi is a real valued number\n",
    "    - objective is to predict yi given a data point xi\n",
    "- Intialize the weights using random normal distribution\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"1.jpg\" alt=\"Drawing\" style=\"width: 500px; height: 400px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- <b>step 1: Computing Loss Function</b>\n",
    "<img src=\"2.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- <b>step 2: Posing Optimization Problem</b>\n",
    "<img src=\"3.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- <b>step 3: Computing Gradient of loss function using chain rule</b>\n",
    "<img src=\"4.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"6.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- <b>step 3: Computing Gradient of loss function using chain rule</b>\n",
    "<img src=\"4.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- <b>step 4: updating weights</b>\n",
    "<img src=\"5.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- <b>repeat step 4 till we reach convergence</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Topics will be covered in the next lecture\n",
    "\n",
    "* Classifiers\n",
    "    - Logistic Regression\n",
    "    - Support Vector Machine\n",
    "    - Multi Layer Perceptron"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
